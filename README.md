# Scaling LLM Inference with Optimized Sample Compute Allocation

Code and generations for this paper (https://arxiv.org/abs/2410.22480) coming soon.
